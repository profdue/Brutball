# app.py - NARRATIVE PREDICTION ENGINE v2.1 - STRESS-TESTED EDITION
# ‚úÖ Implements all stress-test fixes for logical consistency

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import io
import base64

# ==============================================
# ENHANCED NARRATIVE PREDICTION ENGINE
# ‚úÖ Stress-tested with logical consistency fixes
# ==============================================

class EnhancedNarrativePredictionEngine:
    """Enhanced prediction engine with stress-test fixes"""
    
    def __init__(self):
        # Manager style database
        self.manager_db = {
            "Mikel Arteta": {"style": "Possession-based & control", "attack": 9, "defense": 7, "press": 8, "possession": 9, "pragmatic": 6},
            "Unai Emery": {"style": "Balanced/Adaptive", "attack": 8, "defense": 8, "press": 7, "possession": 7, "pragmatic": 7},
            "Andoni Iraola": {"style": "Progressive/Developing", "attack": 7, "defense": 6, "press": 9, "possession": 6, "pragmatic": 5},
            "Keith Andrews": {"style": "Balanced/Adaptive", "attack": 6, "defense": 7, "press": 7, "possession": 6, "pragmatic": 7},
            "Fabian H√ºrzeler": {"style": "Progressive/Developing", "attack": 8, "defense": 6, "press": 7, "possession": 8, "pragmatic": 4},
            "Scott Parker": {"style": "Pragmatic/Defensive", "attack": 5, "defense": 8, "press": 6, "possession": 5, "pragmatic": 8},
            "Enzo Maresca": {"style": "Possession-based & control", "attack": 8, "defense": 7, "press": 7, "possession": 9, "pragmatic": 6},
            "Oliver Glasner": {"style": "Balanced/Adaptive", "attack": 7, "defense": 7, "press": 6, "possession": 7, "pragmatic": 7},
            "David Moyes": {"style": "Pragmatic/Defensive", "attack": 5, "defense": 9, "press": 6, "possession": 5, "pragmatic": 9},
            "Marco Silva": {"style": "Balanced/Adaptive", "attack": 8, "defense": 7, "press": 7, "possession": 7, "pragmatic": 6},
            "Daniel Farke": {"style": "Progressive/Developing", "attack": 8, "defense": 6, "press": 8, "possession": 7, "pragmatic": 5},
            "Arne Slot": {"style": "High press & transition", "attack": 9, "defense": 6, "press": 9, "possession": 7, "pragmatic": 5},
            "Pep Guardiola": {"style": "Possession-based & control", "attack": 10, "defense": 8, "press": 9, "possession": 10, "pragmatic": 4},
            "Ruben Amorim": {"style": "High press & transition", "attack": 8, "defense": 6, "press": 9, "possession": 7, "pragmatic": 5},
            "Eddie Howe": {"style": "High press & transition", "attack": 9, "defense": 6, "press": 9, "possession": 7, "pragmatic": 5},
            "Ange Postecoglou": {"style": "High press & transition", "attack": 9, "defense": 5, "press": 9, "possession": 6, "pragmatic": 4},
            "R√©gis Le Bris": {"style": "Progressive/Developing", "attack": 6, "defense": 7, "press": 7, "possession": 6, "pragmatic": 6},
            "Thomas Frank": {"style": "Balanced/Adaptive", "attack": 7, "defense": 8, "press": 7, "possession": 7, "pragmatic": 7},
            "Graham Potter": {"style": "Balanced/Adaptive", "attack": 7, "defense": 7, "press": 6, "possession": 8, "pragmatic": 7},
            "V√≠tor Pereira": {"style": "Pragmatic/Defensive", "attack": 5, "defense": 8, "press": 5, "possession": 5, "pragmatic": 8}
        }
        
        # Enhanced narrative definitions with stress-test fixes
        self.narratives = {
            "BLITZKRIEG": {
                "description": "Early Domination - Favorite crushes weak opponent",
                "flow": "‚Ä¢ Early pressure from favorite (0-15 mins)\n‚Ä¢ Breakthrough before 30 mins\n‚Ä¢ Opponent confidence collapses after first goal\n‚Ä¢ Additional goals in 35-65 minute window\n‚Ä¢ Game effectively over by 70 mins",
                "betting_markets": ["Favorite to win", "Favorite clean sheet", "First goal before 25:00", "Over 2.5 team goals for favorite", "Favorite -1.5 Asian handicap"],
                "color": "#4CAF50",
                "eligibility_rules": {
                    "min_attack_diff": 2,
                    "min_possession_diff": 2,
                    "max_favorite_odds": 1.60,
                    "min_favorite_prob": 65,
                    "min_tier": 2
                }
            },
            "SHOOTOUT": {
                "description": "End-to-End Chaos - Both teams attack, weak defenses",
                "flow": "‚Ä¢ Fast start from both teams (0-10 mins high intensity)\n‚Ä¢ Early goals probable (first 25 mins)\n‚Ä¢ Lead changes possible throughout match\n‚Ä¢ End-to-end action with both teams committing forward\n‚Ä¢ Late drama very likely (goals after 75 mins)",
                "betting_markets": ["Over 2.5 goals", "BTTS: Yes", "Both teams to score & Over 2.5", "Late goal after 75:00", "Lead changes in match"],
                "color": "#FF5722",
                "btts_range": (65, 75),  # STRESS-TEST FIX: Dynamic range
                "over25_range": (75, 85)
            },
            "SIEGE": {
                "description": "Attack vs Defense - One dominates, other parks bus",
                "flow": "‚Ä¢ Attacker dominates possession (60%+) from start\n‚Ä¢ Defender parks bus in organized low block\n‚Ä¢ Frustration builds as chances are missed\n‚Ä¢ Breakthrough often comes 45-70 mins (not early)\n‚Ä¢ Clean sheet OR counter-attack consolation goal",
                "betting_markets": ["Under 2.5 goals", "Favorite to win", "BTTS: No", "First goal 45-70 mins", "Fewer than 10 corners total"],
                "color": "#2196F3"
            },
            "CHESS_MATCH": {
                "description": "Tactical Stalemate - Both cautious, few chances",
                "flow": "‚Ä¢ Cautious start from both teams (0-30 mins)\n‚Ä¢ Midfield battle dominates, few clear chances\n‚Ä¢ Set pieces become primary scoring threats\n‚Ä¢ First goal (if any) often decisive\n‚Ä¢ Late tactical changes unlikely to alter outcome significantly",
                "betting_markets": ["Under 2.5 goals", "BTTS: No", "0-0 or 1-0 correct score", "Few goals first half", "Under 1.5 goals"],
                "color": "#9C27B0"
            },
            "CONTROLLED_EDGE": {  # NEW NARRATIVE: For Tier 3 mismatches
                "description": "Grinding Advantage - Favorite edges cautious game",
                "flow": "‚Ä¢ Cautious start from both sides\n‚Ä¢ Favorite gradually establishes control\n‚Ä¢ Breakthrough likely 30-60 mins\n‚Ä¢ Limited scoring chances overall\n‚Ä¢ Narrow victory or draw",
                "betting_markets": ["Under 2.5 goals", "BTTS: No", "Favorite to win or draw", "First goal 30-60 mins", "Few corners total"],
                "color": "#FF9800"
            }
        }
    
    # ========== CORE LOGIC WITH STRESS-TEST FIXES ==========
    
    def calculate_favorite_probability(self, home_odds, away_odds):
        """Convert odds to implied probabilities with enhanced accuracy"""
        if home_odds <= 0 or away_odds <= 0:
            return {
                "home_probability": 50,
                "away_probability": 50,
                "favorite_probability": 50,
                "favorite_is_home": True,
                "favorite_strength": "EVEN",
                "favorite_odds": 2.0
            }
        
        home_implied = 1 / home_odds
        away_implied = 1 / away_odds
        total = home_implied + away_implied
        
        home_prob = home_implied / total * 100
        away_prob = away_implied / total * 100
        
        favorite_prob = max(home_prob, away_prob)
        favorite_is_home = home_prob > away_prob
        favorite_odds = home_odds if favorite_is_home else away_odds
        
        # Enhanced strength classification
        if favorite_prob >= 75:
            strength = "ELITE"
        elif favorite_prob >= 65:
            strength = "STRONG"
        elif favorite_prob >= 60:
            strength = "MODERATE"
        elif favorite_prob >= 55:
            strength = "SLIGHT"
        else:
            strength = "EVEN"
        
        return {
            "home_probability": home_prob,
            "away_probability": away_prob,
            "favorite_probability": favorite_prob,
            "favorite_is_home": favorite_is_home,
            "favorite_strength": strength,
            "favorite_odds": favorite_odds,
            "odds_gap": abs(home_odds - away_odds)
        }
    
    def is_blitzkrieg_eligible(self, match_data, prob, tier_level):
        """STRESS-TEST FIX 1: Strict BLITZKRIEG eligibility rules"""
        
        # Get favorite's attack and opponent's defense
        if prob["favorite_is_home"]:
            attack_rating = match_data["home_attack_rating"]
            defense_rating = match_data["away_defense_rating"]
            possession_rating = match_data["home_possession_rating"]
            opp_possession = match_data["away_possession_rating"]
        else:
            attack_rating = match_data["away_attack_rating"]
            defense_rating = match_data["home_defense_rating"]
            possession_rating = match_data["away_possession_rating"]
            opp_possession = match_data["home_possession_rating"]
        
        # Rule 1: Attack differential ‚â• +2
        attack_diff = attack_rating - defense_rating
        if attack_diff < 2:
            return False
        
        # Rule 2: Possession differential ‚â• +2
        possession_diff = possession_rating - opp_possession
        if possession_diff < 2:
            return False
        
        # Rule 3: Odds ‚â§ 1.60
        if prob["favorite_odds"] > 1.60:
            return False
        
        # Rule 4: Favorite probability ‚â• 65%
        if prob["favorite_probability"] < 65:
            return False
        
        # Rule 5: Tier ‚â• 2
        if tier_level < 2:
            return False
        
        return True
    
    def calculate_blitzkrieg_score(self, match_data):
        """Enhanced BLITZKRIEG calculation with eligibility check"""
        score = 0
        
        # Get probability analysis
        prob = self.calculate_favorite_probability(match_data["home_odds"], match_data["away_odds"])
        
        # 1. ELITE FAVORITE (0-30 points) - REDUCED WEIGHT
        if prob["favorite_strength"] == "ELITE":
            score += 30
        elif prob["favorite_strength"] == "STRONG":
            score += 20
        elif prob["favorite_strength"] == "MODERATE":
            score += 10
        
        # 2. ATTACK vs DEFENSE MISMATCH (0-25 points)
        home_attack = match_data["home_attack_rating"]
        away_defense = match_data["away_defense_rating"]
        away_attack = match_data["away_attack_rating"]
        home_defense = match_data["home_defense_rating"]
        
        # Calculate both directions
        home_advantage = home_attack - (10 - away_defense)
        away_advantage = away_attack - (10 - home_defense)
        
        if home_advantage >= 3 or away_advantage >= 3:
            score += 25
        elif home_advantage >= 2 or away_advantage >= 2:
            score += 15
        elif home_advantage >= 1 or away_advantage >= 1:
            score += 5
        
        # 3. FORM DOMINANCE (0-20 points)
        home_form = self.analyze_form(match_data["home_form"])["rating"]
        away_form = self.analyze_form(match_data["away_form"])["rating"]
        form_diff = abs(home_form - away_form)
        score += min(20, form_diff * 2)
        
        # 4. TACTICAL MISMATCH (0-15 points)
        home_press = match_data["home_press_rating"]
        away_press = match_data["away_press_rating"]
        press_diff = abs(home_press - away_press)
        if press_diff >= 3:
            score += 15
        elif press_diff >= 2:
            score += 10
        
        # 5. POSITION GAP (0-10 points)
        position_gap = abs(match_data["home_position"] - match_data["away_position"])
        if position_gap >= 10:
            score += 10
        elif position_gap >= 5:
            score += 5
        
        return min(100, score)
    
    def calculate_shootout_score(self, match_data):
        """Enhanced SHOOTOUT calculation with realistic thresholds"""
        score = 0
        
        # 1. BOTH ATTACKING (0-25 points) - ADJUSTED
        home_attack = match_data["home_attack_rating"]
        away_attack = match_data["away_attack_rating"]
        
        if home_attack >= 8 and away_attack >= 8:
            score += 25  # Both extremely attacking
        elif home_attack >= 7 and away_attack >= 7:
            score += 18  # Both attacking
        elif home_attack >= 6 and away_attack >= 6:
            score += 10  # Both moderately attacking
        
        # 2. BOTH WEAK DEFENSE (0-25 points) - ENHANCED
        home_defense = match_data["home_defense_rating"]
        away_defense = match_data["away_defense_rating"]
        avg_defense = (home_defense + away_defense) / 2
        
        if avg_defense <= 5.5:
            score += 25  # Very weak defenses
        elif avg_defense <= 6.5:
            score += 18  # Weak defenses
        elif avg_defense <= 7.0:
            score += 10  # Below average defenses
        
        # 3. HIGH PRESS BOTH (0-20 points)
        home_press = match_data["home_press_rating"]
        away_press = match_data["away_press_rating"]
        
        if home_press >= 8 and away_press >= 8:
            score += 20  # Both high press
        elif home_press >= 7 and away_press >= 7:
            score += 12  # Both pressing
        elif home_press >= 7 or away_press >= 7:
            score += 5   # At least one high press
        
        # 4. HISTORICAL HIGH SCORING (0-15 points)
        if match_data["last_h2h_goals"] >= 4:
            score += 15
        elif match_data["last_h2h_goals"] >= 3:
            score += 10
        elif match_data["last_h2h_goals"] >= 2:
            score += 5
        
        # 5. BTTS HISTORY + FORM (0-15 points)
        if match_data["last_h2h_btts"] == "Yes":
            score += 8
        
        # Check both teams scoring in recent form
        home_form = match_data["home_form"]
        away_form = match_data["away_form"]
        
        home_scoring = sum(1 for r in home_form[-3:] if r.upper() != 'L')
        away_scoring = sum(1 for r in away_form[-3:] if r.upper() != 'L')
        
        if home_scoring >= 2 and away_scoring >= 2:
            score += 7
        
        return min(100, score)
    
    def calculate_siege_score(self, match_data):
        """Enhanced SIEGE calculation"""
        score = 0
        
        # 1. ATTACKER vs DEFENDER MISMATCH (0-30 points)
        home_attack = match_data["home_attack_rating"]
        away_defense = match_data["away_defense_rating"]
        away_attack = match_data["away_attack_rating"]
        home_defense = match_data["home_defense_rating"]
        
        # Home siege
        if home_attack >= 8 and away_defense >= 8:
            score += 30  # Classic home siege
        elif home_attack >= 7 and away_defense >= 7:
            score += 20
        
        # Away siege
        if away_attack >= 8 and home_defense >= 8:
            score += 25  # Classic away siege
        elif away_attack >= 7 and home_defense >= 7:
            score += 15
        
        # 2. POSSESSION DOMINANCE (0-20 points)
        home_possession = match_data["home_possession_rating"]
        away_possession = match_data["away_possession_rating"]
        
        possession_diff = abs(home_possession - away_possession)
        if possession_diff >= 3:
            score += 20
        elif possession_diff >= 2:
            score += 12
        
        # 3. PRAGMATIC DEFENDER (0-15 points)
        home_pragmatic = match_data["home_pragmatic_rating"]
        away_pragmatic = match_data["away_pragmatic_rating"]
        
        if (home_pragmatic >= 7 and away_pragmatic <= 5) or (away_pragmatic >= 7 and home_pragmatic <= 5):
            score += 15  # One pragmatic, one attacking
        
        # 4. LOW H2H GOALS (0-15 points)
        if match_data["last_h2h_goals"] <= 1:
            score += 15
        elif match_data["last_h2h_goals"] <= 2:
            score += 10
        elif match_data["last_h2h_goals"] <= 3:
            score += 5
        
        # 5. FAVORITE AT HOME (0-10 points)
        prob = self.calculate_favorite_probability(match_data["home_odds"], match_data["away_odds"])
        if prob["favorite_is_home"] and prob["favorite_probability"] >= 60:
            score += 10
        
        return min(100, score)
    
    def calculate_chess_match_score(self, match_data):
        """Enhanced CHESS MATCH calculation"""
        score = 0
        
        # 1. CLOSE MATCH (0-25 points)
        prob = self.calculate_favorite_probability(match_data["home_odds"], match_data["away_odds"])
        favorite_prob = prob["favorite_probability"]
        
        if favorite_prob < 52:  # Very close match
            score += 25
        elif favorite_prob < 55:
            score += 18
        elif favorite_prob < 58:
            score += 10
        
        # 2. BOTH PRAGMATIC/CONSERVATIVE (0-25 points)
        home_pragmatic = match_data["home_pragmatic_rating"]
        away_pragmatic = match_data["away_pragmatic_rating"]
        
        if home_pragmatic >= 7 and away_pragmatic >= 7:
            score += 25  # Both pragmatic
        elif home_pragmatic >= 6 and away_pragmatic >= 6:
            score += 15
        
        # 3. BOTH STRONG DEFENSE (0-20 points)
        home_defense = match_data["home_defense_rating"]
        away_defense = match_data["away_defense_rating"]
        
        if home_defense >= 8 and away_defense >= 8:
            score += 20
        elif home_defense >= 7 and away_defense >= 7:
            score += 12
        
        # 4. BOTH MODERATE/LOW ATTACK (0-15 points)
        home_attack = match_data["home_attack_rating"]
        away_attack = match_data["away_attack_rating"]
        
        if home_attack <= 6 and away_attack <= 6:
            score += 15
        elif home_attack <= 7 and away_attack <= 7:
            score += 8
        
        # 5. HISTORICAL LOW SCORING (0-15 points)
        if match_data["last_h2h_goals"] <= 2:
            score += 15
        elif match_data["last_h2h_goals"] <= 3:
            score += 8
        
        return min(100, score)
    
    def calculate_controlled_edge_score(self, match_data):
        """NEW: Calculate CONTROLLED EDGE narrative score"""
        score = 0
        
        # 1. SLIGHT FAVORITE (0-20 points)
        prob = self.calculate_favorite_probability(match_data["home_odds"], match_data["away_odds"])
        
        if 55 <= prob["favorite_probability"] < 65:
            score += 20
        elif 50 <= prob["favorite_probability"] < 55:
            score += 10
        
        # 2. BALANCED TEAMS (0-20 points)
        home_attack = match_data["home_attack_rating"]
        away_attack = match_data["away_attack_rating"]
        home_defense = match_data["home_defense_rating"]
        away_defense = match_data["away_defense_rating"]
        
        attack_diff = abs(home_attack - away_attack)
        defense_diff = abs(home_defense - away_defense)
        
        if attack_diff <= 2 and defense_diff <= 2:
            score += 20  # Balanced teams
        elif attack_diff <= 3 and defense_diff <= 3:
            score += 10
        
        # 3. MODERATE DEFENSE BOTH (0-15 points)
        if 6 <= home_defense <= 8 and 6 <= away_defense <= 8:
            score += 15
        elif 5 <= home_defense <= 9 and 5 <= away_defense <= 9:
            score += 8
        
        # 4. CONSERVATIVE APPROACH (0-15 points)
        home_pragmatic = match_data["home_pragmatic_rating"]
        away_pragmatic = match_data["away_pragmatic_rating"]
        
        if home_pragmatic >= 5 and away_pragmatic >= 5:
            score += 15
        elif home_pragmatic >= 4 and away_pragmatic >= 4:
            score += 8
        
        # 5. CLOSE TABLE POSITIONS (0-10 points)
        position_gap = abs(match_data["home_position"] - match_data["away_position"])
        if position_gap <= 3:
            score += 10
        elif position_gap <= 6:
            score += 5
        
        # 6. LOW/MODERATE H2H GOALS (0-10 points)
        if match_data["last_h2h_goals"] <= 3:
            score += 10
        elif match_data["last_h2h_goals"] <= 4:
            score += 5
        
        return min(100, score)
    
    def analyze_form(self, form_string):
        """Enhanced form analysis"""
        if not form_string or len(form_string) < 3:
            return {"rating": 5, "confidence": 3, "trend": "stable", "scoring_rate": 0.5}
        
        form_map = {"W": 2, "D": 1, "L": 0}
        points = 0
        scoring_games = 0
        
        for char in form_string.upper():
            if char in form_map:
                points += form_map[char]
                if char != 'L':
                    scoring_games += 1
        
        avg_points = points / len(form_string)
        rating = (avg_points / 2) * 10
        scoring_rate = scoring_games / len(form_string)
        
        # Determine trend from last 3 games
        recent = form_string[-3:] if len(form_string) >= 3 else form_string
        win_count = recent.count('W') + recent.count('w')
        
        if win_count >= 2:
            trend = "improving"
        elif 'W' not in recent and 'w' not in recent:
            trend = "declining"
        else:
            trend = "stable"
        
        return {
            "rating": min(10, rating),
            "confidence": min(10, len(form_string) * 2),
            "trend": trend,
            "points": points,
            "games": len(form_string),
            "scoring_rate": scoring_rate
        }
    
    # ========== DYNAMIC PROBABILITY CALCULATIONS ==========
    
    def calculate_dynamic_btts(self, match_data, narrative):
        """STRESS-TEST FIX 2: Dynamic BTTS probability"""
        home_defense = match_data["home_defense_rating"]
        away_defense = match_data["away_defense_rating"]
        
        # Calculate defensive strength (lower = weaker defense)
        defense_factor = (home_defense + away_defense) / 20  # 0-1 scale
        
        # Calculate attacking strength
        home_attack = match_data["home_attack_rating"]
        away_attack = match_data["away_attack_rating"]
        attack_factor = (home_attack + away_attack) / 20
        
        if narrative == "BLITZKRIEG":
            # Base 30-45% range based on defense
            base_prob = 30 + (15 * (1 - defense_factor))
            # Adjust slightly for attack (more attack = slightly higher BTTS)
            adjusted = base_prob + (5 * attack_factor)
            return min(45, max(30, adjusted))
        
        elif narrative == "SHOOTOUT":
            # Base 65-75% range
            base_prob = 65 + (10 * (1 - defense_factor))
            # Attack heavily influences shootouts
            adjusted = base_prob + (10 * attack_factor)
            return min(80, max(65, adjusted))  # Cap at 80%
        
        elif narrative == "SIEGE":
            # Lower BTTS for sieges
            return 40 * (1 - defense_factor)  # 0-40%
        
        elif narrative == "CHESS_MATCH":
            # Very low BTTS
            return 30 * (1 - defense_factor)  # 0-30%
        
        elif narrative == "CONTROLLED_EDGE":
            # Moderate BTTS
            return 40 + (10 * (1 - defense_factor))  # 40-50%
        
        return 50  # Default
    
    def calculate_dynamic_xg(self, match_data, tier_level, narrative):
        """STRESS-TEST FIX 3: Dynamic expected goals"""
        # Calculate base attack strength
        home_attack = match_data["home_attack_rating"]
        away_attack = match_data["away_attack_rating"]
        avg_attack = (home_attack + away_attack) / 20  # 0-1 scale
        
        # Tier-based ranges
        if tier_level == 1:  # STRONG
            xg_range = (3.2, 3.6)
        elif tier_level == 2:  # MEDIUM
            xg_range = (3.0, 3.4)
        else:  # WEAK
            xg_range = (2.6, 3.1)
        
        # Narrative adjustments
        narrative_adjustments = {
            "BLITZKRIEG": 0.2,   # Higher scoring
            "SHOOTOUT": 0.3,     # Even higher
            "SIEGE": -0.3,       # Lower scoring
            "CHESS_MATCH": -0.5, # Much lower
            "CONTROLLED_EDGE": -0.2
        }
        
        # Calculate base xG within range
        base_xg = xg_range[0] + (xg_range[1] - xg_range[0]) * avg_attack
        
        # Apply narrative adjustment
        adjustment = narrative_adjustments.get(narrative, 0)
        adjusted_xg = base_xg + adjustment
        
        # Ensure reasonable bounds
        return max(1.8, min(4.0, round(adjusted_xg, 1)))
    
    def calculate_over_25_probability(self, expected_goals, narrative):
        """Dynamic Over 2.5 probability"""
        # Base probability from expected goals
        if expected_goals >= 3.5:
            base_prob = 80
        elif expected_goals >= 3.0:
            base_prob = 70
        elif expected_goals >= 2.5:
            base_prob = 60
        elif expected_goals >= 2.0:
            base_prob = 50
        else:
            base_prob = 40
        
        # Narrative adjustments
        narrative_adjustments = {
            "SHOOTOUT": 10,
            "BLITZKRIEG": 5,
            "SIEGE": -15,
            "CHESS_MATCH": -25,
            "CONTROLLED_EDGE": -10
        }
        
        adjustment = narrative_adjustments.get(narrative, 0)
        final_prob = base_prob + adjustment
        
        return max(20, min(90, final_prob))
    
    # ========== MAIN PREDICTION FUNCTION ==========
    
    def predict_match(self, match_data):
        """Enhanced prediction with all stress-test fixes"""
        
        # Calculate all narrative scores
        scores = {
            "BLITZKRIEG": self.calculate_blitzkrieg_score(match_data),
            "SHOOTOUT": self.calculate_shootout_score(match_data),
            "SIEGE": self.calculate_siege_score(match_data),
            "CHESS_MATCH": self.calculate_chess_match_score(match_data),
            "CONTROLLED_EDGE": self.calculate_controlled_edge_score(match_data)
        }
        
        # Determine tier and confidence first (needed for BLITZKRIEG eligibility)
        dominant_score = max(scores.values())
        dominant_narrative = max(scores, key=scores.get)
        
        if dominant_score >= 75:
            tier = "TIER 1 (STRONG)"
            confidence = "High"
            stake = "2-3 units"
            tier_level = 1
        elif dominant_score >= 60:
            tier = "TIER 2 (MEDIUM)"
            confidence = "Medium"
            stake = "1-2 units"
            tier_level = 2
        elif dominant_score >= 50:
            tier = "TIER 3 (WEAK)"
            confidence = "Low"
            stake = "0.5-1 unit"
            tier_level = 3
        else:
            tier = "TIER 4 (AVOID)"
            confidence = "Very Low"
            stake = "No bet"
            tier_level = 4
        
        # STRESS-TEST FIX: Check BLITZKRIEG eligibility
        prob = self.calculate_favorite_probability(match_data["home_odds"], match_data["away_odds"])
        
        if dominant_narrative == "BLITZKRIEG":
            if not self.is_blitzkrieg_eligible(match_data, prob, tier_level):
                # Demote to appropriate narrative
                scores["BLITZKRIEG"] = 0  # Remove from consideration
                
                # Find next best narrative
                dominant_narrative = max(scores, key=scores.get)
                dominant_score = scores[dominant_narrative]
                
                # Recalculate tier based on new dominant narrative
                if dominant_score >= 75:
                    tier = "TIER 1 (STRONG)"
                    confidence = "High"
                    stake = "2-3 units"
                    tier_level = 1
                elif dominant_score >= 60:
                    tier = "TIER 2 (MEDIUM)"
                    confidence = "Medium"
                    stake = "1-2 units"
                    tier_level = 2
                elif dominant_score >= 50:
                    tier = "TIER 3 (WEAK)"
                    confidence = "Low"
                    stake = "0.5-1 unit"
                    tier_level = 3
                else:
                    tier = "TIER 4 (AVOID)"
                    confidence = "Very Low"
                    stake = "No bet"
                    tier_level = 4
        
        # Calculate dynamic probabilities
        expected_goals = self.calculate_dynamic_xg(match_data, tier_level, dominant_narrative)
        btts_prob = self.calculate_dynamic_btts(match_data, dominant_narrative)
        over_25_prob = self.calculate_over_25_probability(expected_goals, dominant_narrative)
        
        # Get narrative info
        narrative_info = self.narratives.get(dominant_narrative, self.narratives["CONTROLLED_EDGE"])
        
        return {
            "match": f"{match_data['home_team']} vs {match_data['away_team']}",
            "date": match_data["date"],
            "scores": scores,
            "dominant_narrative": dominant_narrative,
            "dominant_score": dominant_score,
            "tier": tier,
            "confidence": confidence,
            "tier_level": tier_level,
            "expected_goals": expected_goals,
            "btts_probability": btts_prob,
            "over_25_probability": over_25_prob,
            "stake_recommendation": stake,
            "expected_flow": narrative_info["flow"],
            "betting_markets": narrative_info["betting_markets"],
            "description": narrative_info["description"],
            "narrative_color": narrative_info["color"],
            "probabilities": prob,
            "blitzkrieg_eligible": self.is_blitzkrieg_eligible(match_data, prob, tier_level) if dominant_narrative == "BLITZKRIEG" else False
        }

# ==============================================
# ENHANCED STREAMLIT APP
# ==============================================

def main():
    st.set_page_config(
        page_title="Narrative Prediction Engine v2.1 - Stress-Tested",
        page_icon="‚öΩ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Enhanced CSS with stress-test indicators
    st.markdown("""
    <style>
    .stress-test-pass { border-left: 5px solid #4CAF50 !important; }
    .stress-test-warning { border-left: 5px solid #FF9800 !important; }
    .stress-test-fail { border-left: 5px solid #F44336 !important; }
    .blitzkrieg-eligible { background-color: #E8F5E8 !important; border: 2px solid #4CAF50 !important; }
    .blitzkrieg-ineligible { background-color: #FFEBEE !important; border: 2px solid #F44336 !important; }
    .probability-meter { 
        height: 20px; 
        background: linear-gradient(90deg, #F44336 0%, #FF9800 50%, #4CAF50 100%);
        border-radius: 10px;
        margin: 5px 0;
        position: relative;
    }
    .probability-marker {
        position: absolute;
        top: -5px;
        width: 3px;
        height: 30px;
        background-color: black;
    }
    .consistency-check { padding: 10px; border-radius: 5px; margin: 5px 0; }
    .consistency-good { background-color: #E8F5E8; border-left: 4px solid #4CAF50; }
    .consistency-warning { background-color: #FFF3E0; border-left: 4px solid #FF9800; }
    .consistency-bad { background-color: #FFEBEE; border-left: 4px solid #F44336; }
    </style>
    """, unsafe_allow_html=True)
    
    # App Header
    st.markdown('<h1 class="main-header">‚öΩ NARRATIVE PREDICTION ENGINE v2.1</h1>', unsafe_allow_html=True)
    st.markdown("### **Stress-Tested Edition ‚Ä¢ Enhanced Logic ‚Ä¢ Dynamic Probabilities**")
    
    # Initialize enhanced engine
    engine = EnhancedNarrativePredictionEngine()
    
    # Sidebar
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Configuration")
        
        # Data source
        data_source = st.radio(
            "Data Source",
            ["Upload CSV", "Use Sample Data", "GitHub URL"],
            index=0
        )
        
        df = None
        
        if data_source == "Upload CSV":
            uploaded_file = st.file_uploader("Upload premier_league_matches.csv", type="csv")
            if uploaded_file:
                try:
                    df = pd.read_csv(uploaded_file)
                    st.success(f"‚úÖ Loaded {len(df)} matches")
                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")
        
        elif data_source == "Use Sample Data":
            # Create comprehensive sample data
            sample_matches = [
                {
                    "match_id": "EPL_2025-12-20_MCI_WHU",
                    "league": "Premier League",
                    "date": "2025-12-20",
                    "home_team": "Manchester City",
                    "away_team": "West Ham",
                    "home_position": 1,
                    "away_position": 15,
                    "home_odds": 1.25,
                    "away_odds": 13.00,
                    "home_form": "WWWWW",
                    "away_form": "LLLLL",
                    "home_manager": "Pep Guardiola",
                    "away_manager": "David Moyes",
                    "last_h2h_goals": 4,
                    "last_h2h_btts": "No",
                    "home_manager_style": "Possession-based & control",
                    "away_manager_style": "Pragmatic/Defensive",
                    "home_attack_rating": 10,
                    "away_attack_rating": 5,
                    "home_defense_rating": 8,
                    "away_defense_rating": 9,
                    "home_press_rating": 9,
                    "away_press_rating": 6,
                    "home_possession_rating": 10,
                    "away_possession_rating": 5,
                    "home_pragmatic_rating": 4,
                    "away_pragmatic_rating": 9
                },
                {
                    "match_id": "EPL_2025-12-20_WOL_BRE",
                    "league": "Premier League",
                    "date": "2025-12-20",
                    "home_team": "Wolverhampton",
                    "away_team": "Brentford",
                    "home_position": 10,
                    "away_position": 9,
                    "home_odds": 2.30,
                    "away_odds": 3.10,
                    "home_form": "DLWDL",
                    "away_form": "WDLWD",
                    "home_manager": "V√≠tor Pereira",
                    "away_manager": "Thomas Frank",
                    "last_h2h_goals": 2,
                    "last_h2h_btts": "Yes",
                    "home_manager_style": "Pragmatic/Defensive",
                    "away_manager_style": "Balanced/Adaptive",
                    "home_attack_rating": 5,
                    "away_attack_rating": 7,
                    "home_defense_rating": 8,
                    "away_defense_rating": 8,
                    "home_press_rating": 5,
                    "away_press_rating": 7,
                    "home_possession_rating": 5,
                    "away_possession_rating": 7,
                    "home_pragmatic_rating": 8,
                    "away_pragmatic_rating": 7
                }
            ]
            df = pd.DataFrame(sample_matches)
            st.success(f"‚úÖ Loaded {len(df)} sample matches")
        
        else:  # GitHub URL
            github_url = st.text_input("GitHub Raw CSV URL", value="")
            if github_url and st.button("Load from GitHub"):
                try:
                    df = pd.read_csv(github_url)
                    st.success(f"‚úÖ Loaded {len(df)} matches from GitHub")
                except:
                    st.error("‚ùå Failed to load from GitHub")
        
        # Analysis settings
        st.markdown("### üîß Analysis Settings")
        
        debug_mode = st.checkbox("Show Stress-Test Analysis", value=True)
        show_consistency = st.checkbox("Show Logic Consistency Checks", value=True)
        strict_mode = st.checkbox("Strict BLITZKRIEG Enforcement", value=True)
        
        # Navigation
        st.markdown("### üìã Navigation")
        page = st.radio("Go to", ["Predictions", "Stress-Test Dashboard", "Narrative Guide", "Export"])
    
    # Main content
    if df is not None:
        # Data preview
        with st.expander("üìä Data Preview", expanded=False):
            st.dataframe(df.head())
            
            # Data validation
            required_columns = [
                'home_team', 'away_team', 'date', 'home_odds', 'away_odds',
                'home_attack_rating', 'away_attack_rating', 
                'home_defense_rating', 'away_defense_rating'
            ]
            
            missing = [col for col in required_columns if col not in df.columns]
            if missing:
                st.error(f"‚ùå Missing columns: {', '.join(missing)}")
            else:
                st.success("‚úÖ All required columns present")
        
        # Match selection
        st.markdown("### üéØ Select Matches")
        
        match_options = df.apply(
            lambda row: f"{row['home_team']} vs {row['away_team']} ({row['date']})", 
            axis=1
        ).tolist()
        
        selected_matches = st.multiselect(
            "Choose matches to analyze",
            match_options,
            default=match_options[:min(3, len(match_options))]
        )
        
        # Generate predictions
        if st.button("üöÄ Generate Enhanced Predictions", type="primary"):
            with st.spinner("Running stress-tested analysis..."):
                predictions = []
                consistency_checks = []
                
                for match_str in selected_matches:
                    match_idx = match_options.index(match_str)
                    match_row = df.iloc[match_idx]
                    
                    # Prepare match data
                    match_data = {
                        "home_team": match_row["home_team"],
                        "away_team": match_row["away_team"],
                        "date": match_row["date"],
                        "home_position": int(match_row["home_position"]),
                        "away_position": int(match_row["away_position"]),
                        "home_odds": float(match_row["home_odds"]),
                        "away_odds": float(match_row["away_odds"]),
                        "home_form": str(match_row["home_form"]),
                        "away_form": str(match_row["away_form"]),
                        "home_manager": match_row["home_manager"],
                        "away_manager": match_row["away_manager"],
                        "last_h2h_goals": int(match_row["last_h2h_goals"]),
                        "last_h2h_btts": str(match_row["last_h2h_btts"]),
                        "home_attack_rating": int(match_row["home_attack_rating"]),
                        "away_attack_rating": int(match_row["away_attack_rating"]),
                        "home_defense_rating": int(match_row["home_defense_rating"]),
                        "away_defense_rating": int(match_row["away_defense_rating"]),
                        "home_press_rating": int(match_row["home_press_rating"]),
                        "away_press_rating": int(match_row["away_press_rating"]),
                        "home_possession_rating": int(match_row["home_possession_rating"]),
                        "away_possession_rating": int(match_row["away_possession_rating"]),
                        "home_pragmatic_rating": int(match_row["home_pragmatic_rating"]),
                        "away_pragmatic_rating": int(match_row["away_pragmatic_rating"])
                    }
                    
                    # Get prediction
                    prediction = engine.predict_match(match_data)
                    predictions.append(prediction)
                    
                    # Run consistency checks
                    checks = perform_consistency_checks(prediction, match_data, engine)
                    consistency_checks.append({
                        "match": prediction["match"],
                        "checks": checks
                    })
                
                # Store results
                st.session_state.predictions = predictions
                st.session_state.consistency_checks = consistency_checks
                st.success(f"‚úÖ Generated {len(predictions)} stress-tested predictions")
    
    # Display predictions
    if "predictions" in st.session_state:
        predictions = st.session_state.predictions
        
        if page == "Predictions":
            # Summary dashboard
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                tier1 = sum(1 for p in predictions if p["tier"] == "TIER 1 (STRONG)")
                st.metric("üéØ Tier 1 Predictions", tier1)
            
            with col2:
                avg_xg = sum(p["expected_goals"] for p in predictions) / len(predictions)
                st.metric("üìà Average xG", f"{avg_xg:.2f}")
            
            with col3:
                blitz_count = sum(1 for p in predictions if p["dominant_narrative"] == "BLITZKRIEG")
                st.metric("‚ö° BLITZKRIEG Count", blitz_count)
            
            with col4:
                eligible = sum(1 for p in predictions if p.get("blitzkrieg_eligible", False))
                st.metric("‚úÖ Eligible BLITZKRIEG", eligible)
            
            # Individual predictions
            for i, pred in enumerate(predictions):
                # Determine card class based on stress-test results
                card_class = "prediction-card"
                if pred.get("blitzkrieg_eligible", False) and pred["dominant_narrative"] == "BLITZKRIEG":
                    card_class += " blitzkrieg-eligible"
                elif pred["dominant_narrative"] == "BLITZKRIEG" and not pred.get("blitzkrieg_eligible", False):
                    card_class += " blitzkrieg-ineligible"
                
                st.markdown(f'<div class="{card_class}">', unsafe_allow_html=True)
                
                # Header
                col_h1, col_h2, col_h3 = st.columns([3, 1, 1])
                
                with col_h1:
                    st.markdown(f"### {pred['match']}")
                    st.markdown(f"**Date:** {pred['date']} | **Tier:** {pred['tier']}")
                
                with col_h2:
                    color = pred["narrative_color"]
                    st.markdown(
                        f'<div style="background-color: {color}20; padding: 8px 12px; border-radius: 20px; border: 2px solid {color}; text-align: center;">'
                        f'<strong style="color: {color};">{pred["dominant_narrative"]}</strong><br>'
                        f'<small>{pred["dominant_score"]:.1f}/100</small>'
                        f'</div>',
                        unsafe_allow_html=True
                    )
                
                with col_h3:
                    stake_class = "stake-high" if "2-3" in pred["stake_recommendation"] else \
                                 "stake-medium" if "1-2" in pred["stake_recommendation"] else \
                                 "stake-low"
                    st.markdown(
                        f'<div class="stake-badge {stake_class}" style="text-align: center;">{pred["stake_recommendation"]}</div>',
                        unsafe_allow_html=True
                    )
                    st.markdown(f"**Confidence:** {pred['confidence']}")
                
                # Main content
                col_m1, col_m2 = st.columns(2)
                
                with col_m1:
                    # Narrative scores
                    st.markdown("#### üìä Narrative Scores")
                    for narrative, score in pred["scores"].items():
                        if narrative in engine.narratives:
                            color = engine.narratives[narrative]["color"]
                            st.markdown(f"**{narrative}:** {score:.1f}")
                            st.markdown(f'<div class="score-bar"><div style="width: {score}%; height: 100%; background-color: {color}; border-radius: 10px;"></div></div>', unsafe_allow_html=True)
                    
                    # Key stats
                    st.markdown("#### üìà Key Statistics")
                    
                    col_s1, col_s2, col_s3 = st.columns(3)
                    with col_s1:
                        st.metric("Expected Goals", f"{pred['expected_goals']:.1f}")
                    with col_s2:
                        st.metric("BTTS %", f"{pred['btts_probability']}%")
                    with col_s3:
                        st.metric("Over 2.5 %", f"{pred['over_25_probability']}%")
                
                with col_m2:
                    # Insights
                    st.markdown("#### üí° Insights")
                    st.info(pred["description"])
                    
                    # Expected flow
                    with st.expander("üìà Expected Match Flow"):
                        st.write(pred["expected_flow"])
                    
                    # Betting markets
                    st.markdown("#### üí∞ Recommended Markets")
                    for market in pred["betting_markets"]:
                        st.markdown(f"‚Ä¢ {market}")
                
                # Stress-test analysis
                if debug_mode and "consistency_checks" in st.session_state:
                    checks = st.session_state.consistency_checks[i]["checks"]
                    
                    with st.expander("üîç Stress-Test Analysis", expanded=True):
                        for check in checks:
                            if check["status"] == "PASS":
                                st.markdown(f'<div class="consistency-check consistency-good">‚úÖ {check["check"]}: {check["message"]}</div>', unsafe_allow_html=True)
                            elif check["status"] == "WARNING":
                                st.markdown(f'<div class="consistency-check consistency-warning">‚ö†Ô∏è {check["check"]}: {check["message"]}</div>', unsafe_allow_html=True)
                            else:
                                st.markdown(f'<div class="consistency-check consistency-bad">‚ùå {check["check"]}: {check["message"]}</div>', unsafe_allow_html=True)
                
                st.markdown('</div>', unsafe_allow_html=True)
        
        elif page == "Stress-Test Dashboard":
            # Comprehensive stress-test analysis
            st.markdown("## üî¨ Stress-Test Dashboard")
            
            # Overall statistics
            total_matches = len(predictions)
            blitz_matches = [p for p in predictions if p["dominant_narrative"] == "BLITZKRIEG"]
            eligible_blitz = [p for p in blitz_matches if p.get("blitzkrieg_eligible", False)]
            
            col_s1, col_s2, col_s3, col_s4 = st.columns(4)
            
            with col_s1:
                st.metric("Total Predictions", total_matches)
            
            with col_s2:
                st.metric("BLITZKRIEG Predictions", len(blitz_matches))
            
            with col_s3:
                st.metric("Eligible BLITZKRIEG", len(eligible_blitz))
            
            with col_s4:
                if len(blitz_matches) > 0:
                    eligibility_rate = len(eligible_blitz) / len(blitz_matches) * 100
                    st.metric("Eligibility Rate", f"{eligibility_rate:.1f}%")
                else:
                    st.metric("Eligibility Rate", "N/A")
            
            # Probability distribution
            st.markdown("### üìä Probability Distribution Analysis")
            
            # Create visualization
            btts_values = [p["btts_probability"] for p in predictions]
            over25_values = [p["over_25_probability"] for p in predictions]
            xg_values = [p["expected_goals"] for p in predictions]
            
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=("BTTS Probability", "Over 2.5 Probability", "Expected Goals", "Narrative Distribution"),
                specs=[[{"type": "histogram"}, {"type": "histogram"}],
                      [{"type": "histogram"}, {"type": "pie"}]]
            )
            
            # BTTS histogram
            fig.add_trace(
                go.Histogram(x=btts_values, name="BTTS %", marker_color="#2196F3"),
                row=1, col=1
            )
            
            # Over 2.5 histogram
            fig.add_trace(
                go.Histogram(x=over25_values, name="Over 2.5 %", marker_color="#4CAF50"),
                row=1, col=2
            )
            
            # xG histogram
            fig.add_trace(
                go.Histogram(x=xg_values, name="xG", marker_color="#FF9800"),
                row=2, col=1
            )
            
            # Narrative pie chart
            narrative_counts = {}
            for pred in predictions:
                narrative = pred["dominant_narrative"]
                narrative_counts[narrative] = narrative_counts.get(narrative, 0) + 1
            
            fig.add_trace(
                go.Pie(
                    labels=list(narrative_counts.keys()),
                    values=list(narrative_counts.values()),
                    marker_colors=[engine.narratives[n]["color"] for n in narrative_counts.keys()]
                ),
                row=2, col=2
            )
            
            fig.update_layout(height=600, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
            
            # Detailed analysis
            st.markdown("### üìã Detailed Consistency Checks")
            
            for i, pred in enumerate(predictions):
                with st.expander(f"{pred['match']} - {pred['dominant_narrative']}"):
                    if "consistency_checks" in st.session_state:
                        checks = st.session_state.consistency_checks[i]["checks"]
                        for check in checks:
                            status_icon = "‚úÖ" if check["status"] == "PASS" else "‚ö†Ô∏è" if check["status"] == "WARNING" else "‚ùå"
                            st.write(f"{status_icon} **{check['check']}**: {check['message']}")
                    
                    # Show raw scores
                    st.markdown("**Raw Narrative Scores:**")
                    for narrative, score in pred["scores"].items():
                        st.write(f"- {narrative}: {score:.1f}")
        
        elif page == "Narrative Guide":
            # Enhanced narrative guide
            st.markdown("## üìñ Enhanced Narrative Guide")
            
            for name, info in engine.narratives.items():
                col_g1, col_g2 = st.columns([1, 2])
                
                with col_g1:
                    st.markdown(
                        f'<div style="background-color: {info["color"]}15; padding: 20px; border-radius: 10px; border-left: 5px solid {info["color"]};">'
                        f'<h3 style="color: {info["color"]}; margin-top: 0;">{name}</h3>'
                        f'<p><strong>{info["description"]}</strong></p>'
                        f'</div>',
                        unsafe_allow_html=True
                    )
                
                with col_g2:
                    with st.expander(f"Detailed Rules & Examples", expanded=False):
                        st.markdown("**Expected Match Flow:**")
                        st.write(info["flow"])
                        
                        st.markdown("**Typical Characteristics:**")
                        
                        if name == "BLITZKRIEG":
                            st.write("""
                            - Favorite odds ‚â§ 1.60
                            - Attack differential ‚â• +2
                            - Possession differential ‚â• +2  
                            - Favorite probability ‚â• 65%
                            - Tier ‚â• 2 (Medium+ confidence)
                            - Expected BTTS: 30-45%
                            - Expected xG: 3.2-3.6
                            """)
                        
                        elif name == "SHOOTOUT":
                            st.write("""
                            - Both teams attack rating ‚â• 7
                            - Average defense rating ‚â§ 6.5
                            - Both teams pressing style
                            - Historical high scoring
                            - Expected BTTS: 65-75%
                            - Expected xG: 3.4-3.8
                            """)
                        
                        elif name == "CONTROLLED_EDGE":
                            st.write("""
                            - Slight favorite (55-65% probability)
                            - Balanced teams (rating differences ‚â§ 2)
                            - Moderate defense both sides
                            - Conservative tactical approach
                            - Expected BTTS: 40-50%
                            - Expected xG: 2.6-3.1
                            """)
                        
                        st.markdown("**Recommended Markets:**")
                        for market in info["betting_markets"]:
                            st.write(f"‚Ä¢ {market}")
                
                st.markdown("---")
        
        elif page == "Export":
            # Export functionality
            st.markdown("## üìä Export Predictions")
            
            export_data = []
            for pred in predictions:
                export_data.append({
                    "Match": pred["match"],
                    "Date": pred["date"],
                    "Predicted_Narrative": pred["dominant_narrative"],
                    "Narrative_Score": pred["dominant_score"],
                    "Tier": pred["tier"],
                    "Confidence": pred["confidence"],
                    "Expected_Goals": pred["expected_goals"],
                    "BTTS_Probability": pred["btts_probability"],
                    "Over_25_Probability": pred["over_25_probability"],
                    "Stake_Recommendation": pred["stake_recommendation"],
                    "Blitzkrieg_Eligible": pred.get("blitzkrieg_eligible", False),
                    "Probability_Favorite": pred["probabilities"]["favorite_probability"],
                    "Favorite_Strength": pred["probabilities"]["favorite_strength"]
                })
            
            export_df = pd.DataFrame(export_data)
            
            # Preview
            st.dataframe(export_df)
            
            # Download
            csv = export_df.to_csv(index=False)
            b64 = base64.b64encode(csv.encode()).decode()
            href = f'<a href="data:file/csv;base64,{b64}" download="stress_tested_predictions_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv">üì• Download CSV</a>'
            st.markdown(href, unsafe_allow_html=True)
            
            # Summary statistics
            st.markdown("### üìà Export Summary")
            col_e1, col_e2, col_e3 = st.columns(3)
            
            with col_e1:
                avg_xg = export_df["Expected_Goals"].mean()
                st.metric("Average xG", f"{avg_xg:.2f}")
            
            with col_e2:
                avg_btts = export_df["BTTS_Probability"].mean()
                st.metric("Average BTTS %", f"{avg_btts:.1f}%")
            
            with col_e3:
                blitz_count = len(export_df[export_df["Predicted_Narrative"] == "BLITZKRIEG"])
                st.metric("BLITZKRIEG Count", blitz_count)
    
    else:
        # Initial state
        st.info("üëà **Upload a CSV file or use sample data to get started**")
        
        # Show what's new
        with st.expander("üéØ What's New in v2.1", expanded=True):
            st.markdown("""
            ### üö® Stress-Test Fixes Implemented:
            
            **1. BLITZKRIEG Eligibility Rules** ‚úÖ
            - Attack differential ‚â• +2 required
            - Possession differential ‚â• +2 required  
            - Odds ‚â§ 1.60 threshold
            - Favorite probability ‚â• 65%
            - Tier ‚â• 2 confidence required
            
            **2. Dynamic Probability Ranges** ‚úÖ
            - BTTS: 30-45% for BLITZKRIEG (not fixed 30%)
            - BTTS: 65-75% for SHOOTOUT (not fixed 75%)
            - xG varies by tier and attack ratings
            
            **3. New Narrative: CONTROLLED_EDGE** ‚úÖ
            - For Tier 3 mismatches
            - Balanced teams, slight favorites
            - Grinding advantage style
            
            **4. Logic Consistency Checks** ‚úÖ
            - Validates narrative-probability alignment
            - Checks tier-narrative consistency
            - Verifies betting market relevance
            """)
            
            st.success("**Result:** More accurate, logically consistent predictions with reduced false positives")

def perform_consistency_checks(prediction, match_data, engine):
    """Run comprehensive consistency checks"""
    checks = []
    
    # 1. Check BLITZKRIEG eligibility
    if prediction["dominant_narrative"] == "BLITZKRIEG":
        prob = prediction["probabilities"]
        eligible = engine.is_blitzkrieg_eligible(match_data, prob, prediction["tier_level"])
        
        if eligible:
            checks.append({
                "check": "BLITZKRIEG Eligibility",
                "status": "PASS",
                "message": "Meets all eligibility criteria"
            })
        else:
            checks.append({
                "check": "BLITZKRIEG Eligibility",
                "status": "FAIL",
                "message": "Does not meet eligibility criteria - narrative adjusted"
            })
    
    # 2. Check tier-narrative consistency
    if prediction["tier"] == "TIER 3 (WEAK)" and prediction["dominant_narrative"] == "BLITZKRIEG":
        checks.append({
            "check": "Tier-Narrative Consistency",
            "status": "WARNING",
            "message": "Tier 3 with BLITZKRIEG narrative may indicate overconfidence"
        })
    else:
        checks.append({
            "check": "Tier-Narrative Consistency",
            "status": "PASS",
            "message": f"Tier {prediction['tier_level']} aligns with {prediction['dominant_narrative']}"
        })
    
    # 3. Check probability coherence
    if prediction["dominant_narrative"] == "BLITZKRIEG":
        if prediction["btts_probability"] > 45:
            checks.append({
                "check": "BTTS Probability Coherence",
                "status": "WARNING",
                "message": f"BTTS {prediction['btts_probability']}% high for BLITZKRIEG"
            })
        else:
            checks.append({
                "check": "BTTS Probability Coherence",
                "status": "PASS",
                "message": f"BTTS {prediction['btts_probability']}% appropriate for BLITZKRIEG"
            })
    
    elif prediction["dominant_narrative"] == "SHOOTOUT":
        if prediction["btts_probability"] < 65:
            checks.append({
                "check": "BTTS Probability Coherence",
                "status": "WARNING",
                "message": f"BTTS {prediction['btts_probability']}% low for SHOOTOUT"
            })
        else:
            checks.append({
                "check": "BTTS Probability Coherence",
                "status": "PASS",
                "message": f"BTTS {prediction['btts_probability']}% appropriate for SHOOTOUT"
            })
    
    # 4. Check xG range appropriateness
    if prediction["tier_level"] == 1:
        xg_range = (3.2, 3.6)
    elif prediction["tier_level"] == 2:
        xg_range = (3.0, 3.4)
    else:
        xg_range = (2.6, 3.1)
    
    if xg_range[0] <= prediction["expected_goals"] <= xg_range[1]:
        checks.append({
            "check": "xG Range Appropriateness",
            "status": "PASS",
            "message": f"xG {prediction['expected_goals']} within tier range {xg_range}"
        })
    else:
        checks.append({
            "check": "xG Range Appropriateness",
            "status": "WARNING",
            "message": f"xG {prediction['expected_goals']} outside tier range {xg_range}"
        })
    
    # 5. Check score confidence alignment
    if prediction["dominant_score"] >= 75 and prediction["confidence"] != "High":
        checks.append({
            "check": "Score-Confidence Alignment",
            "status": "WARNING",
            "message": f"Score {prediction['dominant_score']} suggests higher confidence than {prediction['confidence']}"
        })
    elif prediction["dominant_score"] < 60 and prediction["confidence"] == "High":
        checks.append({
            "check": "Score-Confidence Alignment",
            "status": "WARNING",
            "message": f"Score {prediction['dominant_score']} suggests lower confidence than {prediction['confidence']}"
        })
    else:
        checks.append({
            "check": "Score-Confidence Alignment",
            "status": "PASS",
            "message": f"Score {prediction['dominant_score']} aligns with {prediction['confidence']} confidence"
        })
    
    return checks

if __name__ == "__main__":
    main()
